{"cells":[{"cell_type":"code","source":["1+1"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: 2</div>"]}}],"execution_count":1},{"cell_type":"code","source":["from pyspark.sql.functions import lit,col,concat, substring\nNO_OF_ROWS = 100000\ndfIds = spark.range(NO_OF_ROWS).withColumn(\"IDAsString\", concat(lit(\"Str=\"), col(\"id\")))\ndisplay(dfIds.limit(5))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>IDAsString</th></tr></thead><tbody><tr><td>0</td><td>Str=0</td></tr><tr><td>1</td><td>Str=1</td></tr><tr><td>2</td><td>Str=2</td></tr><tr><td>3</td><td>Str=3</td></tr><tr><td>4</td><td>Str=4</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["path = \"/tmp/parquet/10MIDs\"\ndfIds.write.mode(\"Overwrite\").parquet(path)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["dfBeforeAppend = spark.read.parquet(path)\nprint(\"No Rows before append:\", dfBeforeAppend.count())"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">No Rows before append: 100000\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["%sql\n-- DROP IF EXIST\nDROP TABLE IF EXISTS IDS;\n-- Skapa en tabell som pekar på PARQUET\nCREATE TABLE IDS\n    USING parquet\n    OPTIONS (\n      path \"/tmp/parquet/10MIDs\"\n    )"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":5},{"cell_type":"code","source":["%sql\nSELECT COUNT(*) FROM IDS"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>100000</td></tr></tbody></table></div>"]}}],"execution_count":6},{"cell_type":"code","source":["from pyspark.sql import functions as f\n# Append Rows\nNO_APPEEND_NEW_ROWS = 10000\ndfAppendRows = spark.range(NO_OF_ROWS + NO_APPEEND_NEW_ROWS).filter(\"id >= {rows}\".format(rows=NO_OF_ROWS)).withColumn(\"IDAsString\", f.concat(f.lit(\"Str=\"), f.col(\"id\")))\ndfAppendRows.write.mode(\"Append\").parquet(path)\ndfAfterAppend = spark.read.parquet(path)\nprint(\"NoROws after\", dfAfterAppend.count())"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">NoROws after 120000\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["%sql\nSELECT COUNT(*) FROM IDS"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>100000</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"code","source":["%sql\nREFRESH TABLE IDS"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"code","source":["%sql\nSELECT COUNT(*) FROM IDS"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th></tr></thead><tbody><tr><td>120000</td></tr></tbody></table></div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["# Append data to partitions using parquet"],"metadata":{}},{"cell_type":"code","source":["# Create a col to partition on\n# Just take last digit in id as partition id\ndfId = spark.read.parquet(path)\ndfId3 = dfId.withColumn(\"PartitionId\", f.substring(f.col(\"id\"), -1, 1))\n# substring(column, -1, 1)\ndisplay(dfId3.limit(7))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>IDAsString</th><th>PartitionId</th></tr></thead><tbody><tr><td>50000</td><td>Str=50000</td><td>0</td></tr><tr><td>50001</td><td>Str=50001</td><td>1</td></tr><tr><td>50002</td><td>Str=50002</td><td>2</td></tr><tr><td>50003</td><td>Str=50003</td><td>3</td></tr><tr><td>50004</td><td>Str=50004</td><td>4</td></tr><tr><td>50005</td><td>Str=50005</td><td>5</td></tr><tr><td>50006</td><td>Str=50006</td><td>6</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Write IDS partitioned on last digit\npathPar = \"/tmp/parquet/IDSPartitioned/\"\ndfId3.write.partitionBy(\"PartitionId\").mode(\"Overwrite\").parquet(pathPar)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS IDPARTITIONED;\n-- Create table on top of partitioned data\nCREATE TABLE IDPARTITIONED (id long, IDAsString string, PartitionId int)\n    USING parquet\n    OPTIONS (\n      path \"/tmp/parquet/IDSPartitioned/\"\n    )\n    partitioned by (PartitionId)\n    -- When the table schema is not provided, schema and partition columns will be inferred"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":14},{"cell_type":"code","source":["%sql\nMSCK REPAIR TABLE IDPARTITIONED"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":15},{"cell_type":"code","source":["%sql\nselect count(*), PartitionId from IDPARTITIONED group by PartitionId order by PartitionId limit 7\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th><th>PartitionId</th></tr></thead><tbody><tr><td>12000</td><td>0</td></tr><tr><td>12000</td><td>1</td></tr><tr><td>12000</td><td>2</td></tr><tr><td>12000</td><td>3</td></tr><tr><td>12000</td><td>4</td></tr><tr><td>12000</td><td>5</td></tr><tr><td>12000</td><td>6</td></tr></tbody></table></div>"]}}],"execution_count":16},{"cell_type":"code","source":["%fs\nls /mnt/datasetsneugen2/parquet/IDSPartitioned/"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/*/</td><td>*/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=0/</td><td>PartitionId=0/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=1/</td><td>PartitionId=1/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=2/</td><td>PartitionId=2/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=3/</td><td>PartitionId=3/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=4/</td><td>PartitionId=4/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=5/</td><td>PartitionId=5/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=6/</td><td>PartitionId=6/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=7/</td><td>PartitionId=7/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=8/</td><td>PartitionId=8/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/PartitionId=9/</td><td>PartitionId=9/</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/_SUCCESS</td><td>_SUCCESS</td><td>0</td></tr><tr><td>dbfs:/mnt/datasetsneugen2/parquet/IDSPartitioned/_committed_4328684544942137249</td><td>_committed_4328684544942137249</td><td>35</td></tr></tbody></table></div>"]}}],"execution_count":17},{"cell_type":"code","source":["dfReadPar = spark.read.parquet(pathPar)\ndisplay(dfReadPar.groupBy(\"PartitionId\").count())"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PartitionId</th><th>count</th></tr></thead><tbody><tr><td>6</td><td>12000</td></tr><tr><td>5</td><td>12000</td></tr><tr><td>9</td><td>12000</td></tr><tr><td>8</td><td>12000</td></tr><tr><td>7</td><td>12000</td></tr><tr><td>2</td><td>12000</td></tr><tr><td>1</td><td>12000</td></tr><tr><td>3</td><td>12000</td></tr><tr><td>0</td><td>12000</td></tr><tr><td>4</td><td>12000</td></tr></tbody></table></div>"]}}],"execution_count":18},{"cell_type":"code","source":["# filter out ids with partition 0 and 1 and append to original parquet\ndfFilter01 = dfId3.filter(\"PartitionId == 0 or PartitionId == 1\")\n# append these rows to original parquet\ndfFilter01.write.partitionBy(\"PartitionId\").mode(\"Append\").parquet(pathPar)\n# Test result\ndfReadPar = spark.read.parquet(pathPar)\ndisplay(dfReadPar.groupBy(\"PartitionId\").count())"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>PartitionId</th><th>count</th></tr></thead><tbody><tr><td>6</td><td>12000</td></tr><tr><td>5</td><td>12000</td></tr><tr><td>9</td><td>12000</td></tr><tr><td>4</td><td>12000</td></tr><tr><td>8</td><td>12000</td></tr><tr><td>7</td><td>12000</td></tr><tr><td>2</td><td>12000</td></tr><tr><td>1</td><td>24000</td></tr><tr><td>3</td><td>12000</td></tr><tr><td>0</td><td>24000</td></tr></tbody></table></div>"]}}],"execution_count":19},{"cell_type":"code","source":["%sql\n-- check table\nselect count(*), PartitionId from IDPARTITIONED group by PartitionId order by PartitionId"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th><th>PartitionId</th></tr></thead><tbody><tr><td>12000</td><td>0</td></tr><tr><td>12000</td><td>1</td></tr><tr><td>12000</td><td>2</td></tr><tr><td>12000</td><td>3</td></tr><tr><td>12000</td><td>4</td></tr><tr><td>12000</td><td>5</td></tr><tr><td>12000</td><td>6</td></tr><tr><td>12000</td><td>7</td></tr><tr><td>12000</td><td>8</td></tr><tr><td>12000</td><td>9</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"code","source":["%sql\nMSCK REPAIR TABLE IDPARTITIONED;\nselect count(*), PartitionId from IDPARTITIONED group by PartitionId order by PartitionId\n-- We should now be able to see the changes"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>count(1)</th><th>PartitionId</th></tr></thead><tbody><tr><td>24000</td><td>0</td></tr><tr><td>24000</td><td>1</td></tr><tr><td>12000</td><td>2</td></tr><tr><td>12000</td><td>3</td></tr><tr><td>12000</td><td>4</td></tr><tr><td>12000</td><td>5</td></tr><tr><td>12000</td><td>6</td></tr><tr><td>12000</td><td>7</td></tr><tr><td>12000</td><td>8</td></tr><tr><td>12000</td><td>9</td></tr></tbody></table></div>"]}}],"execution_count":21},{"cell_type":"markdown","source":["#What if we tried to update specific rows?\nParquet does not allow updates. That means we would have some options:\n- Rewritee all data\n- Read exisitng data and create a new updated version of the data and rewrite all data\n- FIgure out in what partition we want to change and do the above for only the partition\n\nWe have our data partitioned on the Partition ID."],"metadata":{}},{"cell_type":"code","source":["%sql\nselect * from IDPARTITIONED where id < 30 limit 7"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>IDAsString</th><th>PartitionId</th></tr></thead><tbody><tr><td>3</td><td>Str=3</td><td>3</td></tr><tr><td>13</td><td>Str=13</td><td>3</td></tr><tr><td>23</td><td>Str=23</td><td>3</td></tr><tr><td>9</td><td>Str=9</td><td>9</td></tr><tr><td>19</td><td>Str=19</td><td>9</td></tr><tr><td>29</td><td>Str=29</td><td>9</td></tr><tr><td>2</td><td>Str=2</td><td>2</td></tr></tbody></table></div>"]}}],"execution_count":23},{"cell_type":"code","source":["# What if we would like to update the row where id = 50013 or id = 50033 and we want to add a string fixed to the IDAsString\n# Both are in partition 3 so we can read the partion 3 only and write the update back\n\ndfPartition = spark.sql(\"select * from IDPARTITIONED where PartitionId = 3\")\ndfPartition.show(5)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----------+-----------+\n   id|IDAsString|PartitionId|\n+-----+----------+-----------+\n50003| Str=50003|          3|\n50013| Str=50013|          3|\n50023| Str=50023|          3|\n50033| Str=50033|          3|\n50043| Str=50043|          3|\n+-----+----------+-----------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["# Some logic for update\ndfChange = dfPartition.filter(\"id = 50013 or id = 50033\")\ndfChange.show()\n\ndfFixed = dfChange.withColumn(\"IDAsString\", f.concat(f.col(\"IDAsString\"), f.lit(\"_fixed\")))\ndfFixed.show()"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----------+-----------+\n   id|IDAsString|PartitionId|\n+-----+----------+-----------+\n50013| Str=50013|          3|\n50033| Str=50033|          3|\n+-----+----------+-----------+\n\n+-----+---------------+-----------+\n   id|     IDAsString|PartitionId|\n+-----+---------------+-----------+\n50013|Str=50013_fixed|          3|\n50033|Str=50033_fixed|          3|\n+-----+---------------+-----------+\n\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["# Take original data and put chnages in and write back\n# Here dropping rows that should be updated and then adding by union. (Remember there is no update - a DF is immuatble)\n# Get a new DF with the rows that should be updated\ndfFiltered = dfPartition.filter(\"id != 50033 and id != 50013\")\n# Add the updated rows to a new DF\ndfUpdatedDF = dfFiltered.union(dfFixed)\ndisplay(dfUpdatedDF.filter(\"id > 50012\").orderBy(\"id\").limit(7))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>IDAsString</th><th>PartitionId</th></tr></thead><tbody><tr><td>50013</td><td>Str=50013_fixed</td><td>3</td></tr><tr><td>50023</td><td>Str=50023</td><td>3</td></tr><tr><td>50033</td><td>Str=50033_fixed</td><td>3</td></tr><tr><td>50043</td><td>Str=50043</td><td>3</td></tr><tr><td>50053</td><td>Str=50053</td><td>3</td></tr><tr><td>50063</td><td>Str=50063</td><td>3</td></tr><tr><td>50073</td><td>Str=50073</td><td>3</td></tr></tbody></table></div>"]}}],"execution_count":26},{"cell_type":"code","source":["# Overwrite the correct parition with our new DF containing all data fro partion 3\ndfUpdatedDF.write.mode(\"overwrite\").parquet(pathPar + \"PartitionId={partion_name}/\".format(partion_name=\"3\"))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"code","source":["# The rows in partitio 3 are updated in our final table.\ndisplay(spark.read.parquet(pathPar).filter(\"id < 50015 and id > 50011 or id < 50034 and id > 50032\").orderBy(\"id\"))"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>IDAsString</th><th>PartitionId</th></tr></thead><tbody><tr><td>50012</td><td>Str=50012</td><td>2</td></tr><tr><td>50013</td><td>Str=50013_fixed</td><td>3</td></tr><tr><td>50014</td><td>Str=50014</td><td>4</td></tr><tr><td>50033</td><td>Str=50033_fixed</td><td>3</td></tr></tbody></table></div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["#### Note - It´s easier to append data as you can write append to a specific partition as we showed above. The updates are harder as you are forces to rewrite at least the full partition."],"metadata":{}},{"cell_type":"markdown","source":["#### Note 2 - DELTA - By using the delta file format you can do upserts into different partitions much easier and not risking ovwerwriting your data by using time travel and ACID transactions.\nAlso table meta-data will be updated and in sync when using delta."],"metadata":{}}],"metadata":{"name":"Append to Parquet and partitions","notebookId":2547973803932281},"nbformat":4,"nbformat_minor":0}
